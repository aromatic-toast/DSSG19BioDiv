{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from geojson import GeometryCollection\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point data to geoJSON\n",
    "import random\n",
    "import sqlite3\n",
    "\n",
    "df_red = pd.read_csv(\"redlist_assessments.csv\")\n",
    "\n",
    "# Assume: RedList scientific correspond to UBC species\n",
    "red_sciNames = df_red.scientificName\n",
    "\n",
    "def some(x, n):\n",
    "    return x.loc[random.sample(x.index, n)]\n",
    "\n",
    "def pointCSVtoJSON(filename, num_rows=0):\n",
    "    df = pd.read_csv(filename, delimiter=\"\\t\", low_memory=False)\n",
    "    if (num_rows):\n",
    "        df = some(df, num_rows)\n",
    "    geometry = [Point(xy) for xy in zip (df['decimalLongitude'], df['decimalLatitude'])]\n",
    "    geo_df = gpd.GeoDataFrame(df, geometry = geometry, crs = {'init': 'epsg:4326'})\n",
    "    \n",
    "    # gbif_geo_df = gbif_geo_df[gbif_geo_df['species'].isin(red_sciNames)]\n",
    "    geo_df['redList'] = geo_df.apply(lambda x: int(x['species']in red_sciNames.values), 1).values\n",
    "    \n",
    "    \n",
    "    # Common Names ITIS\n",
    "    # # Get names of all tables\n",
    "    # c = conn.cursor()\n",
    "    # c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    # print(c.fetchall())\n",
    "\n",
    "    db = sqlite3.connect('ITIS.sqlite')\n",
    "    df_commons = pd.read_sql_query(\"SELECT * from vernaculars\", db)\n",
    "    df_species = pd.read_sql_query(\"SELECT * from longnames\", db)\n",
    "    # table.to_csv(table_name + '.csv', index_label='index')\n",
    "\n",
    "    df_species = df_species[df_species['completename'].isin(geo_df.species)]\n",
    "    df_commons = df_commons[df_commons['tsn'].isin(df_species.tsn)]\n",
    "\n",
    "    # df_species.index = df_species.tsn.values\n",
    "    # df_commons.index = df_commons.tsn.values\n",
    "\n",
    "    df_commons['common'] = df_commons[['language', 'vernacular_name']].apply(lambda x: ':'.join(x), axis=1)\n",
    "\n",
    "    df_commons = df_commons[['tsn', 'common']]\n",
    "\n",
    "    df_commons = df_commons.groupby(['tsn'])['common'].apply(', '.join).reset_index()\n",
    "    # df_commons.index = df_commons.tsn.values\n",
    "\n",
    "    df_species = df_species[df_species['tsn'].isin(df_commons.tsn.values)]\n",
    "\n",
    "    df_common_species = df_species.merge(df_commons, on=\"tsn\")\n",
    "\n",
    "    \n",
    "    df_common_species = df_common_species.rename({'completename': 'species'}, axis=1) \n",
    "    df_common_species = df_common_species.drop(['tsn'], 1)\n",
    "\n",
    "    species = set(geo_df.species.unique())\n",
    "    species_in_itis = set(df_common_species.species.unique())\n",
    "    diff = list(species - species_in_itis)\n",
    "    diff = {df_common_species.columns[0]: diff, df_common_species.columns[1]: 'unkown'}\n",
    "    df = pd.DataFrame.from_dict(diff)\n",
    "    df_species = pd.concat([df_common_species, df], sort = False)\n",
    "\n",
    "    geo_df = geo_df.merge(df_species, on=\"species\")\n",
    "    \n",
    "\n",
    "    geo_df.to_file(\"leaflet/\" + filename.split('.')[0] + '.geojson', driver=\"GeoJSON\")\n",
    "    \n",
    "    return geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_geo_df = pointCSVtoJSON('gbif_tot.csv', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbif_geo_df.to_file(\"leaflet/\" +'red.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHP data to geoJSON\n",
    "def fix_crs(map_ob):\n",
    "    return map_ob.to_crs({'init': 'epsg:4326'})\n",
    "str_map = gpd.read_file(\"ecological_reserves/BC_Eco_Reserves.shp\")\n",
    "str_map = fix_crs(str_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GeoJSON does not support multipolygon. Doesn't work\n",
    "# str_map.to_file(\"leaflet/UBC_poly.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# # fiona doesn't work\n",
    "# import fiona\n",
    "# import json\n",
    "\n",
    "# with fiona.open('ecological_reserves/BC_Eco_Reserves.shp') as source:\n",
    "#     records = list(source)\n",
    "# geo_json = {\"type\": \"FeatureCollection\",\"features\": records}\n",
    "# with open('leaflet/UBC_poly.geojson', 'w') as fp:\n",
    "#     json.dump(geo_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert multipolygon to single polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_series = str_map.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geom_apply(x):\n",
    "    try:\n",
    "        return list(x)\n",
    "    except TypeError:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_series = geom_series.apply(geom_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_series = geom_series.apply(pd.Series).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick but loses properties\n",
    "# list_poly = list(geom_series)\n",
    "# geoms = GeometryCollection(list_poly)\n",
    "# geo_file = geojson.dumps(geoms)\n",
    "# with open(\"leaflet/UBC_poly.geojson\", \"w\") as text_file:\n",
    "#     text_file.write(geo_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful! Deep copy required here to avoid chaining\n",
    "\n",
    "df = pd.DataFrame(columns=str_map.columns)\n",
    "for ind, poly in geom_series.iteritems():\n",
    "    curr_row = str_map.loc[ind[0]].copy(deep=True)\n",
    "    curr_row['geometry'] = poly\n",
    "    df = df.append(curr_row)\n",
    "\n",
    "df_gpd = gpd.GeoDataFrame(df,geometry = df.geometry, crs = {'init': 'epsg:4326'})\n",
    "df_gpd.to_file(\"leaflet/UBC_poly.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gbif_geo_df.to_file('leaflet/gbif_tot.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupy2)",
   "language": "python",
   "name": "jupy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
